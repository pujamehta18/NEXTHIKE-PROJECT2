{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d97fdd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sachin\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sachin\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "368488b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\sachin\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sachin\\anaconda3\\lib\\site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\sachin\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sachin\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sachin\\anaconda3\\lib\\site-packages (from requests) (2022.9.14)\n"
     ]
    }
   ],
   "source": [
    "! pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e785a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary libraries/modules for web scrapping and word frequency count task\n",
    "import sys\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d939d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New News in the python.org section\n",
      "1.Announcing Python Software Foundation Fellow Members for Q3 2023! ðŸŽ‰\n",
      "2.Announcing the Deputy Developer in Residence and the Supporting Developer in Residence\n",
      "3.Python 3.13.0 alpha 3 is now available.\n",
      "4.EUâ€™s Cyber Resilience Act Passes with Wins for Open Source\n",
      "5.Python Software Foundation - December 2023 Newsletter\n"
     ]
    }
   ],
   "source": [
    "# Define a function to get the latest articles from python.org\n",
    "def get_latest_python_articles():\n",
    "    \n",
    "    # Set the url to the python.org website\n",
    "    url = \"https://www.python.org/\"\n",
    "    \n",
    "    # Send a GET request to the url and store the response\n",
    "    response=requests.get(url)\n",
    "    \n",
    "    # Check if the response status code is 200 (OK)\n",
    "    if response.status_code == 200:\n",
    "        \n",
    "        # Parse the response text using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text,\"html.parser\")\n",
    "        \n",
    "        # Create an empty list to store the article titles\n",
    "        latest_articles = []\n",
    "\n",
    "        # Loop through the list items in the blog-widget section\n",
    "        for article in soup.select(\".blog-widget li\"):\n",
    "            \n",
    "            # Get the text of the anchor tag and strip any whitespace\n",
    "            title=article.a.text.strip()\n",
    "            \n",
    "            # Append the title to the latest_articles list\n",
    "            latest_articles.append(title)\n",
    "            \n",
    "        # Return the latest_articles list\n",
    "        return latest_articles\n",
    "    \n",
    "    # If the response status code is not 200, print an error message and return an empty list\n",
    "    else:\n",
    "        print(f\"fail to retrieve informatio.status code:{response.status_code}\")\n",
    "        return[]     \n",
    "\n",
    "# Check if the script is run as the main module\n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    # Call the get_latest_python_articles function and store the result\n",
    "    python_articles=get_latest_python_articles()\n",
    "    \n",
    "    # Check if the python_articles list is not empty\n",
    "    if python_articles:\n",
    "        \n",
    "        # Print a message indicating the new articles\n",
    "        print(\"New News in the python.org section\")\n",
    "        \n",
    "        # Loop through the python_articles list with the index and the article title\n",
    "        for index,article in enumerate(python_articles,1):\n",
    "            \n",
    "            # Print the index and the article title\n",
    "            print(f\"{index}.{article}\")\n",
    "            \n",
    "    # If the python_articles list is empty, print a message indicating no articles found\n",
    "    else:\n",
    "        print(\"no articles found\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf5fe525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word frequencies in the scraped text:\n",
      "announcing: 2\n",
      "python: 3\n",
      "software: 2\n",
      "foundation: 2\n",
      "fellow: 1\n",
      "members: 1\n",
      "for: 2\n",
      "q3: 1\n",
      "2023: 2\n",
      "the: 2\n",
      "deputy: 1\n",
      "developer: 2\n",
      "in: 2\n",
      "residence: 2\n",
      "and: 1\n",
      "supporting: 1\n",
      "3130: 1\n",
      "alpha: 1\n",
      "3: 1\n",
      "is: 1\n",
      "now: 1\n",
      "available: 1\n",
      "eus: 1\n",
      "cyber: 1\n",
      "resilience: 1\n",
      "act: 1\n",
      "passes: 1\n",
      "with: 1\n",
      "wins: 1\n",
      "open: 1\n",
      "source: 1\n",
      "december: 1\n",
      "newsletter: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def get_word_frequencies(articles):\n",
    "    # Combine all articles into one string\n",
    "    text = ' '.join(articles)\n",
    "\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
    "\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "\n",
    "    # Count the frequency of each word\n",
    "    word_frequencies = Counter(words)\n",
    "\n",
    "    return word_frequencies\n",
    "\n",
    "word_frequencies = get_word_frequencies(python_articles)\n",
    "print(\"\\nWord frequencies in the scraped text:\")\n",
    "for word, frequency in word_frequencies.items():\n",
    "    print(f\"{word}: {frequency}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536f5313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
